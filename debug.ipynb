{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytz\n",
    "import datetime as dt\n",
    "\n",
    "def _fix_doubling(df: pd.DataFrame, col: str, date_col: str = \"date\", start_date: str = \"2017-09-27\", end_date: str = \"2018-06-12\") -> pd.DataFrame:\n",
    "    \"\"\"Fixes doubling happening in a dataframe for a specific column\"\"\"\n",
    "    print(f\"Fixing doubling for {col}.\")\n",
    "    \n",
    "    start_date = pd.to_datetime(start_date).date()\n",
    "    end_date = pd.to_datetime(end_date).date()\n",
    "\n",
    "    date_range_mask = (df[date_col] <= end_date) & (df[date_col] >= start_date)\n",
    "    df.loc[date_range_mask, col] = df.loc[date_range_mask, col] / 2\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def _is_daylight_savings(date, timezone: str = \"US/Eastern\") -> int:\n",
    "    \"\"\"Checks if a given date is in daylight savings time for a specific timezone.\"\"\"\n",
    "    # date = date.date()\n",
    "    tz = pytz.timezone(timezone)\n",
    "    dt = tz.localize(datetime.combine(date, datetime.min.time()), is_dst=None)\n",
    "    return int(dt.dst() != timedelta(0))\n",
    "\n",
    "\n",
    "def _process_interval_data(csv_df, interval_minutes=5):\n",
    "    def round_time_to_nearest_interval(time):\n",
    "        minutes = (time.hour * 60) + time.minute\n",
    "        rounded_minutes = round(minutes / interval_minutes) * interval_minutes\n",
    "        return dt.time(hour=(rounded_minutes // 60) % 24, minute=rounded_minutes % 60)\n",
    "\n",
    "    def add_12_hours_to_time(time_obj):\n",
    "        datetime_obj = dt.datetime.combine(dt.date(1, 1, 1), time_obj)\n",
    "        datetime_obj += dt.timedelta(hours=12)\n",
    "        return datetime_obj.time()\n",
    "    \n",
    "    df = csv_df.copy()\n",
    "    \n",
    "    df = df[[\"startDate\", \"endDate\", \"value\"]]\n",
    "    df['startDate'] = pd.to_datetime(df['startDate']) - pd.Timedelta(hours=12)\n",
    "    df['date'] = df['startDate'].dt.date\n",
    "    df['time'] = df['startDate'].dt.time.map(round_time_to_nearest_interval)\n",
    "    df_grouped = df.groupby(['date', 'time'])['value'].mean().reset_index()\n",
    "    df_pivot = df_grouped.pivot_table(index='date', columns='time', values='value').reset_index()\n",
    "\n",
    "    df_pivot.set_index('date', inplace=True)\n",
    "    time_start = dt.time(hour=9) #9PM Start\n",
    "    time_end = dt.time(hour=21) # 9AM End\n",
    "    df_filtered = df_pivot.loc[:, (df_pivot.columns >= time_start) & (df_pivot.columns <= time_end)]\n",
    "    df_filtered = df_filtered.rename(columns=add_12_hours_to_time)\n",
    "    df_filtered.iloc[:, 1:] = df_filtered.iloc[:, 1:].interpolate(axis=1).ffill(axis=1).bfill(axis=1)\n",
    "    df_filtered = df_filtered.reset_index()\n",
    "\n",
    "    #final_df = unique_dates.merge(df_filtered, on=\"date\", how=\"left\")\n",
    "    \n",
    "    df_filtered.columns = [str(name).replace(':', '_') for name in df_filtered.columns]\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "def _calculate_night_hours(orig_df):\n",
    "    df = orig_df.copy()\n",
    "    \n",
    "    df['startDate'] = pd.to_datetime(df['startDate']).dt.tz_localize(None)\n",
    "    df['endDate'] = pd.to_datetime(df['endDate']).dt.tz_localize(None)\n",
    "    \n",
    "    df = df.sort_values(by=['startDate', 'endDate'])\n",
    "    \n",
    "    # Get the date range in the dataframe\n",
    "    min_date = df['startDate'].min().date()\n",
    "    max_date = df['endDate'].max().date()\n",
    "\n",
    "    # Initialize an empty list to store the results\n",
    "    results = []\n",
    "\n",
    "    # Loop through each date in the range\n",
    "    if pd.notnull(min_date) and pd.notnull(max_date):\n",
    "\n",
    "        for date in pd.date_range(min_date, max_date):\n",
    "            # startSleep time boundaries - Based on analysis of train_detailed\n",
    "            start_day = pd.Timestamp.combine(date, pd.Timestamp('21:30:00').time())\n",
    "            end_day = pd.Timestamp.combine(date + pd.DateOffset(1), pd.Timestamp('02:30:00').time())\n",
    "            # endSleep time boundaries - Based on analysis of train_detailed\n",
    "            start_night = pd.Timestamp.combine(date + pd.DateOffset(1), pd.Timestamp('05:30:00').time())\n",
    "            end_night = pd.Timestamp.combine(date + pd.DateOffset(1), pd.Timestamp('10:30:00').time())\n",
    "            # print(f'date {date}, start sleep {start_day}, end sleep {end_day}, start awake {start_night}, end awake {end_night}')\n",
    "\n",
    "            # Filter the dataframe for start of sleep\n",
    "            mask_startSleep_startDate = (df['startDate'] >= start_day) & (df['startDate'] <= end_day)\n",
    "            filtered_startSleep_startDate = df[mask_startSleep_startDate]\n",
    "\n",
    "            mask_startSleep_endDate = (df['endDate'] >= start_day) & (df['endDate'] <= end_day)\n",
    "            filtered_startSleep_endDate = df[mask_startSleep_endDate]\n",
    "\n",
    "            # Filter the dataframe for end of sleep\n",
    "            mask_endSleep_startDate = (df['startDate'] >= start_night) & (df['startDate'] <= end_night)\n",
    "            filtered_endSleep_startDate = df[mask_endSleep_startDate]\n",
    "\n",
    "            mask_endSleep_endDate = (df['endDate'] >= start_night) & (df['endDate'] <= end_night)\n",
    "            filtered_endSleep_endDate = df[mask_endSleep_endDate]\n",
    "\n",
    "            # Append the results to the list\n",
    "            results.append({\n",
    "                'date': date,\n",
    "                'startSleep_min_startDate': filtered_startSleep_startDate['startDate'].min(),\n",
    "                'startSleep_max_startDate': filtered_startSleep_startDate['startDate'].max() ,\n",
    "                'startSleep_min_endDate': filtered_startSleep_endDate['endDate'].min(),\n",
    "                'startSleep_max_endDate': filtered_startSleep_endDate['endDate'].max(), \n",
    "                'endSleep_min_startDate': filtered_endSleep_startDate['startDate'].min(),\n",
    "                'endSleep_max_startDate': filtered_endSleep_startDate['startDate'].max(),\n",
    "                'endSleep_min_endDate': filtered_endSleep_endDate['endDate'].min(),\n",
    "                'endSleep_max_endDate': filtered_endSleep_endDate['endDate'].max(),\n",
    "            })\n",
    "\n",
    "        # Convert the results to a dataframe and return\n",
    "        result_df = pd.DataFrame(results)\n",
    "\n",
    "        start_sleep_columns = [\n",
    "            \"startSleep_min_startDate\",\n",
    "            \"startSleep_max_startDate\",\n",
    "            \"startSleep_min_endDate\",\n",
    "            \"startSleep_max_endDate\",\n",
    "        ]   \n",
    "\n",
    "        end_sleep_columns = [\n",
    "            \"endSleep_min_startDate\",\n",
    "            \"endSleep_max_startDate\",\n",
    "            \"endSleep_min_endDate\",\n",
    "            \"endSleep_max_endDate\",\n",
    "        ]\n",
    "\n",
    "        # Clips (calculated from last 3 months)\n",
    "        avg_sleep = 6.78525641025641\n",
    "        max_sleep = 7.734282511512526\n",
    "        min_sleep = 5.836230309000293\n",
    "\n",
    "        for i, start_col in enumerate(start_sleep_columns):\n",
    "            for j, end_col in enumerate(end_sleep_columns):\n",
    "                result_df[f\"diff_{i}_{j}\"] = (result_df[end_col] - result_df[start_col]).dt.total_seconds() / 3600\n",
    "                result_df[f\"diff_{i}_{j}\"] = ((avg_sleep + result_df[f\"diff_{i}_{j}\"])/2).clip(lower=min_sleep, upper=max_sleep)\n",
    "\n",
    "        for col in start_sleep_columns:\n",
    "            result_df[f\"{col}_hr\"] = result_df[col].dt.hour + result_df[col].dt.minute / 60 + result_df[col].dt.second / 3600\n",
    "            result_df[f\"{col}_hr\"] = result_df[f\"{col}_hr\"].apply(lambda x: x + 24 if x < 12 else x) # If the hour is less than 12, add 24 to it\n",
    "\n",
    "        for col in end_sleep_columns:\n",
    "            result_df[f\"{col}_hr\"] = result_df[col].dt.hour + result_df[col].dt.minute / 60 + result_df[col].dt.second / 3600\n",
    "\n",
    "        result_df = result_df.drop(columns = ['startSleep_min_startDate', 'startSleep_max_startDate', 'startSleep_min_endDate', 'startSleep_max_endDate', 'endSleep_min_startDate', 'endSleep_max_startDate', 'endSleep_min_endDate', 'endSleep_max_endDate']).reset_index(drop=True)\n",
    "    \n",
    "    else:\n",
    "        result_df = pd.DataFrame(columns=['date', 'diff_0_0', 'diff_0_1', 'diff_0_2', 'diff_0_3', 'diff_1_0', 'diff_1_1', 'diff_1_2', 'diff_1_3', 'diff_2_0', 'diff_2_1', 'diff_2_2', 'diff_2_3', 'diff_3_0', 'diff_3_1', 'diff_3_2', 'diff_3_3', 'startSleep_min_startDate_hr', 'startSleep_max_startDate_hr', 'startSleep_min_endDate_hr', 'startSleep_max_endDate_hr', 'endSleep_min_startDate_hr', 'endSleep_max_startDate_hr', 'endSleep_min_endDate_hr', 'endSleep_max_endDate_hr'])\n",
    "    \n",
    "    return result_df\n",
    "        \n",
    "def _create_xml_features(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Create XML features from the provided CSV file.\"\"\"\n",
    "    print(f\"Featurizing {path}\")\n",
    "    csv_df = pd.read_csv(path, low_memory=False)\n",
    "    base_name = os.path.basename(path).split(\".\")[0]\n",
    "    \n",
    "\n",
    "    value = \"totalEnergyBurned\" if base_name == \"Workout\" else \"value\"\n",
    "    agg_func = \"mean\" if base_name == \"BodyMassIndex\" else \"sum\"\n",
    "    \n",
    "    csv_df[\"startDate\"] = pd.to_datetime(csv_df[\"startDate\"]).dt.tz_convert(\"US/Eastern\")\n",
    "    csv_df[\"endDate\"] = pd.to_datetime(csv_df[\"endDate\"]).dt.tz_convert(\"US/Eastern\")\n",
    "    csv_df[\"date\"] = (pd.to_datetime(csv_df[\"startDate\"])- pd.to_timedelta('12:00:00')).dt.date\n",
    "    csv_df[\"time\"] = pd.to_datetime(csv_df[\"startDate\"]).dt.time\n",
    "    \n",
    "    csv_df = csv_df.sort_values(by=['startDate', 'endDate'])\n",
    "    \n",
    "    csv_df[\"hours_between\"] = (csv_df[\"startDate\"].shift(-1) - csv_df[\"endDate\"]).dt.total_seconds() / 3600\n",
    "    csv_df['is_night'] = (csv_df['startDate'] - pd.Timedelta(hours=12)).dt.date == csv_df['startDate'].dt.date\n",
    "    \n",
    "    groupby_agg = {\n",
    "        \"startDate\": [\"max\", \"min\"],\n",
    "        \"endDate\": [\"max\", \"min\"],\n",
    "        f\"{value}\": agg_func,\n",
    "        \"hours_between\" : \"max\"\n",
    "    }\n",
    "\n",
    "    df = csv_df.groupby(\"date\").agg(groupby_agg).reset_index()\n",
    "    df.columns = [\"_\".join(tup).rstrip(\"_\") for tup in df.columns.values]\n",
    "\n",
    "    df = df.rename(columns={f\"{value}_{agg_func}\": base_name})\n",
    "    df = df.rename(columns={\"hours_between_max\": \"slp_\"+base_name+\"_max_hrs_between\"})\n",
    "    \n",
    "    # Sum hours between if is_night is True \n",
    "    def sum_night_hours(group):\n",
    "        return group.loc[group['is_night'], 'hours_between'].sum()\n",
    "\n",
    "    df[f\"slp_{base_name}_sum_hrs_between\"] = csv_df.groupby(\"date\").apply(sum_night_hours).values\n",
    "    \n",
    "    # Count hours between if is_night is True (sleep interruptions)\n",
    "    def count_night_hours(group):\n",
    "        return group.loc[group['is_night'], 'hours_between'].count()\n",
    "    \n",
    "    df[f\"slp_{base_name}_count_hrs_between\"] = csv_df.groupby(\"date\").apply(count_night_hours).values\n",
    "    \n",
    "    # Sum hours_between when HeartRate is less than 60\n",
    "    csv_df[\"hours_inbetween\"] = (csv_df[\"endDate\"] - csv_df[\"startDate\"]).dt.total_seconds() / 3600\n",
    "    def custom_features(group, value, operator):\n",
    "        if operator == \"<\":\n",
    "            return group.loc[group['value'] < value, 'hours_inbetween'].sum()\n",
    "        elif operator == \">\":\n",
    "            return group.loc[group['value'] > value, 'hours_inbetween'].sum()\n",
    "        else:\n",
    "            raise ValueError(\"Invalid operator. Only '<' or '>' are allowed.\")\n",
    "    \n",
    "    if base_name == \"HeartRate\":\n",
    "        df[f\"slp_{base_name}_est\"] = csv_df.groupby(\"date\").apply(lambda group: custom_features(group, 52.71599196743369, \"<\")).values # slp_HeartRate_est\n",
    "    elif base_name == \"OxygenSaturation\":\n",
    "        df[f\"slp_{base_name}_est\"] = csv_df.groupby(\"date\").apply(lambda group: custom_features(group, 0.9695523020888221, \"<\")).values # slp_OxygenSaturation_est\n",
    "    elif base_name == \"RespiratoryRate\":\n",
    "        df[f\"slp_{base_name}_est\"] = csv_df.groupby(\"date\").apply(lambda group: custom_features(group, 17.292111591847622, \"<\")).values # slp_RespiratoryRate_est\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    for time_col in [\"startDate_max\", \"startDate_min\", \"endDate_max\", \"endDate_min\"]:\n",
    "        # Hours\n",
    "        col_prefix = f\"{base_name}_{time_col}_\"\n",
    "        df[col_prefix + \"hr\"] = df[time_col].dt.hour\n",
    "        \n",
    "    \n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.date\n",
    "    \n",
    "    # Check if csv_df \"value\" is numeric, and if so, calculate interval data\n",
    "    if pd.to_numeric(csv_df[\"value\"], errors='coerce').notnull().all():\n",
    "\n",
    "        # Time intervals\n",
    "        intervals = _process_interval_data(csv_df)\n",
    "        intervals = intervals.add_prefix(f\"slp_{base_name}_\")\n",
    "        intervals = intervals.rename(columns={f\"slp_{base_name}_date\": \"date\"})\n",
    "        intervals[\"date\"] = pd.to_datetime(intervals[\"date\"]).dt.date\n",
    "        df = df.merge(intervals, how=\"left\", on = \"date\")\n",
    "\n",
    "\n",
    "    # Night Hours\n",
    "    if base_name == \"RespiratoryRate\":\n",
    "        csv_df = csv_df[csv_df[\"value\"] < 18.0]\n",
    "    elif base_name == \"OxygenSaturation\":\n",
    "        csv_df = csv_df[csv_df[\"value\"] < 0.97]\n",
    "    elif base_name == \"HeartRate\":\n",
    "        csv_df = csv_df[csv_df[\"value\"] < 51.0]\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    night_hours_df = _calculate_night_hours(csv_df)\n",
    "    night_hours_df = night_hours_df.add_prefix(f\"slp_{base_name}_\")\n",
    "    night_hours_df = night_hours_df.rename(columns={f\"slp_{base_name}_date\": \"date\"})\n",
    "    night_hours_df[\"date\"] = pd.to_datetime(night_hours_df[\"date\"]).dt.date\n",
    "    df = df.merge(night_hours_df, how=\"left\", on = \"date\")\n",
    "\n",
    "\n",
    "    df = _fix_doubling(df, base_name)\n",
    "    df = df.drop(columns=[\"startDate_max\", \"startDate_min\", \"endDate_max\", \"endDate_min\"]) \n",
    "    \n",
    "    # Drop non-numeric columns\n",
    "    # df = df[df.columns[df.columns.isin(['date']) | df.dtypes.isin(['number'])]]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xml_data(path = \"./data/xml_export\", xml_files_names = [\"RespiratoryRate\"]):\n",
    "    \"\"\"Featurize XML data from given path.\"\"\"\n",
    "    print(\"Creating XML data\")\n",
    "    \n",
    "    xml_files_names = [os.path.join(path, f\"{xml_file}.csv\") for xml_file in xml_files_names]\n",
    "\n",
    "    # Create DataFrame with date column from 1/1/2015 to 12/31/2023\n",
    "    xml_data = pd.DataFrame({\"date\": pd.date_range(start=\"1/1/2015\", end=\"12/31/2023\", freq=\"D\")})\n",
    "    xml_data[\"date\"] = xml_data[\"date\"].dt.date\n",
    "\n",
    "    # Parse each xml file output and merge with the train data\n",
    "    for xml_file in xml_files_names:\n",
    "        \n",
    "        xml = _workout_features(xml_file) if \"Workout\" in xml_file else _create_xml_features(xml_file) \n",
    "        \n",
    "        xml[\"date\"] = pd.to_datetime(xml[\"date\"]).dt.date\n",
    "        \n",
    "        xml_data = pd.merge(xml_data, xml, on=\"date\", how=\"outer\")\n",
    "    \n",
    "    return xml_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2021, 10, 25)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test.slp_RespiratoryRate_diff_0_3.isna().value_counts()\n",
    "\n",
    "# Max date where slp_RespiratoryRate_diff_0_3 is not NaN\n",
    "test[test.slp_RespiratoryRate_diff_0_3.notna()].date.min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating XML data\n",
      "Featurizing ./data/xml_export/RespiratoryRate.csv\n",
      "Fixing doubling for RespiratoryRate.\n"
     ]
    }
   ],
   "source": [
    "test = create_xml_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing doubling for sleep_hours.\n",
      "Start date: 2015-06-08, End date: 2021-12-31\n",
      "Missing days: 87\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/train.csv\")\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.date\n",
    "\n",
    "# Filter date on >= self.start_date\n",
    "#df = df[df[\"date\"] >= pd.to_datetime(self.start_date)].reset_index(drop=True)\n",
    "df = df[df[\"date\"] >= pd.to_datetime(\"2015-06-01\").date()].reset_index(drop=True)\n",
    "\n",
    "\n",
    "df = df.sort_values(by=\"date\")\n",
    "df = _fix_doubling(df, \"sleep_hours\")\n",
    "\n",
    "start_date, end_date = df[\"date\"].min(), df[\"date\"].max()\n",
    "print(f\"Start date: {start_date}, End date: {end_date}\")\n",
    "\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq=\"D\")\n",
    "date_range = pd.DataFrame({\"date\": date_range})\n",
    "date_range[\"date\"] = date_range[\"date\"].dt.date\n",
    "\n",
    "df = date_range.merge(df, on=\"date\", how=\"left\")\n",
    "print(f\"Missing days: {df.sleep_hours.isna().sum()}\")\n",
    "\n",
    "df = df.merge(test, on=\"date\", how=\"left\") #Add XML data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2021, 12, 31)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pog4-sleep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
